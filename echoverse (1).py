# -*- coding: utf-8 -*-
"""echoverse.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14KLEognCc9GuWZDHeQDPtpOICbyJ9Kif
"""

!pip install -U transformers

print("hello world")

"""## Local Inference on GPU
Model page: https://huggingface.co/ibm-granite/granite-3.3-2b-instruct

‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/ibm-granite/granite-3.3-2b-instruct)
			and/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè
"""

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("text-generation", model="ibm-granite/granite-3.3-2b-instruct")
messages = [
    {"role": "user", "content": "Who are you?"},
]
pipe(messages)

# Load model directly
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("ibm-granite/granite-3.3-2b-instruct")
model = AutoModelForCausalLM.from_pretrained("ibm-granite/granite-3.3-2b-instruct")
messages = [
    {"role": "user", "content": "Who are you?"},
]
inputs = tokenizer.apply_chat_template(
	messages,
	add_generation_prompt=True,
	tokenize=True,
	return_dict=True,
	return_tensors="pt",
).to(model.device)

outputs = model.generate(**inputs, max_new_tokens=40)
print(tokenizer.decode(outputs[0][inputs["input_ids"].shape[-1]:]))

!pip install transformers accelerate gradio gtts --quiet

import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from gtts import gTTS
import tempfile
import os

# -----------------------------
# Load IBM Granite 3.3 2B Instruct
# -----------------------------
model_name = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype="auto"
)

generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=500,
    temperature=0.7,
    do_sample=True
)

# -----------------------------
# Function: Tone Adaptive Rewriting
# -----------------------------
def rewrite_text(text, tone):
    prompt = (
        f"Rewrite the following text in a {tone} tone. "
        f"Keep the original meaning but enhance style.\n\n"
        f"Original Text:\n{text}\n\n"
        f"Rewritten ({tone} tone):"
    )

    output = generator(prompt)[0]["generated_text"]

    # Remove prompt from output
    if "Rewritten" in output:
        output = output.split("Rewritten")[1]
        output = output.replace(f"({tone} tone):", "").strip()

    return output

# -----------------------------
# Function: Convert rewritten text into audio
# -----------------------------
def make_audio(text):
    tts = gTTS(text)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(temp_file.name)
    return temp_file.name

# -----------------------------
# Gradio App Logic
# -----------------------------
def process(text_input, tone):
    if not text_input.strip():
        return "Please enter text.", None

    rewritten = rewrite_text(text_input, tone)
    audio_path = make_audio(rewritten)

    return rewritten, audio_path


# -----------------------------
# Gradio UI
# -----------------------------
with gr.Blocks() as demo:
    gr.Markdown("<h1>üéß EchoVerse ‚Äì AI Audiobook Generator</h1>")
    gr.Markdown("Generate tone-adapted rewritten text + audio narration.")

    with gr.Row():
        text_input = gr.Textbox(
            label="Enter your text",
            placeholder="Paste your content here...",
            lines=10
        )

        tone = gr.Dropdown(
            ["Neutral", "Suspenseful", "Inspiring"],
            label="Select Tone",
            value="Neutral"
        )

    submit_btn = gr.Button("Generate Audiobook")

    rewritten_output = gr.Textbox(
        label="Rewritten Text (Tone Adapted)",
        lines=10
    )

    audio_output = gr.Audio(
        label="Generated Audio",
        type="filepath"
    )

    submit_btn.click(
        process,
        inputs=[text_input, tone],
        outputs=[rewritten_output, audio_output]
    )

demo.launch(share=True)